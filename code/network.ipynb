{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras.backend\n",
    "import keras.callbacks\n",
    "import keras.layers\n",
    "import keras.models\n",
    "import keras.optimizers\n",
    "\n",
    "import helper.loss_functions\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel/__main__.py:4: DeprecationWarning: PyUnicode_AsEncodedObject() is deprecated; use PyUnicode_AsEncodedString() to encode from str to bytes or PyCodec_Encode() for generic encoding\n"
     ]
    }
   ],
   "source": [
    "# set up config for GPU\n",
    "configuration = tf.ConfigProto()\n",
    "configuration.gpu_options.allow_growth = True\n",
    "configuration.gpu_options.visible_device_list = \"2\"\n",
    "session = tf.Session(config = configuration)\n",
    "\n",
    "# apply session\n",
    "keras.backend.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dim1 = 64\n",
    "dim2 = 64\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 100\n",
    "\n",
    "path_x = '../data/dummy/x.npy'\n",
    "path_y = '../data/dummy/y.npy'\n",
    "\n",
    "tb_log_dir = '../logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = keras.layers.Input((dim1, dim2, 1))\n",
    "\n",
    "options_conv = {\"activation\": \"relu\", \"kernel_size\": (5, 5), \"padding\": \"same\"}\n",
    "options_max_pool = {\"pool_size\" : (2,2), \"strides\" : (2,2)}\n",
    "\n",
    "y = keras.layers.BatchNormalization()(x)\n",
    "\n",
    "y = keras.layers.Conv2D(16, **options_conv)(y)\n",
    "y = keras.layers.MaxPool2D(**options_max_pool)(y)\n",
    "y = keras.layers.BatchNormalization()(y)\n",
    "\n",
    "y = keras.layers.Conv2D(32, **options_conv)(y)\n",
    "y = keras.layers.MaxPool2D(**options_max_pool)(y)\n",
    "y = keras.layers.BatchNormalization()(y)\n",
    "\n",
    "y = keras.layers.Conv2D(64, **options_conv)(y)\n",
    "y = keras.layers.MaxPool2D(**options_max_pool)(y)\n",
    "y = keras.layers.BatchNormalization()(y)\n",
    "\n",
    "y = keras.layers.Conv2D(64, **options_conv)(y)\n",
    "\n",
    "y = keras.layers.UpSampling2D()(y)\n",
    "y = keras.layers.BatchNormalization()(y)\n",
    "y = keras.layers.Conv2D(32, **options_conv)(y)\n",
    "\n",
    "y = keras.layers.UpSampling2D()(y)\n",
    "y = keras.layers.BatchNormalization()(y)\n",
    "y = keras.layers.Conv2D(16, **options_conv)(y)\n",
    "\n",
    "y = keras.layers.UpSampling2D()(y)\n",
    "y = keras.layers.BatchNormalization()(y)\n",
    "y = keras.layers.Conv2D(8, **options_conv)(y)\n",
    "\n",
    "y = keras.layers.Conv2D(2, **options_conv)(y)\n",
    "\n",
    "y = keras.layers.Activation('softmax')(y)\n",
    "\n",
    "model = keras.models.Model(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64, 64, 1)         4         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 16)        416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 64)          102464    \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 32)        51232     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 16)        12816     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 64, 64, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 64, 64, 8)         3208      \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 64, 64, 2)         402       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64, 64, 2)         0         \n",
      "=================================================================\n",
      "Total params: 235,534.0\n",
      "Trainable params: 235,084.0\n",
      "Non-trainable params: 450.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = np.load(path_x)\n",
    "Y = np.load(path_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.sgd()\n",
    "loss = helper.loss_functions.crazyloss\n",
    "callbacks = [keras.callbacks.TensorBoard(tb_log_dir, histogram_freq=10)]\n",
    "model.compile(optimizer, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "INFO:tensorflow:Summary name batch_normalization_1/gamma:0 is illegal; using batch_normalization_1/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_1/beta:0 is illegal; using batch_normalization_1/beta_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_1/moving_mean:0 is illegal; using batch_normalization_1/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_1/moving_variance:0 is illegal; using batch_normalization_1/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_1/kernel:0 is illegal; using conv2d_1/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_1/bias:0 is illegal; using conv2d_1/bias_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_2/gamma:0 is illegal; using batch_normalization_2/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_2/beta:0 is illegal; using batch_normalization_2/beta_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_2/moving_mean:0 is illegal; using batch_normalization_2/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_2/moving_variance:0 is illegal; using batch_normalization_2/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_2/kernel:0 is illegal; using conv2d_2/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_2/bias:0 is illegal; using conv2d_2/bias_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_3/gamma:0 is illegal; using batch_normalization_3/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_3/beta:0 is illegal; using batch_normalization_3/beta_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_3/moving_mean:0 is illegal; using batch_normalization_3/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_3/moving_variance:0 is illegal; using batch_normalization_3/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_3/kernel:0 is illegal; using conv2d_3/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_3/bias:0 is illegal; using conv2d_3/bias_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_4/gamma:0 is illegal; using batch_normalization_4/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_4/beta:0 is illegal; using batch_normalization_4/beta_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_4/moving_mean:0 is illegal; using batch_normalization_4/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_4/moving_variance:0 is illegal; using batch_normalization_4/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_4/kernel:0 is illegal; using conv2d_4/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_4/bias:0 is illegal; using conv2d_4/bias_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_5/gamma:0 is illegal; using batch_normalization_5/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_5/beta:0 is illegal; using batch_normalization_5/beta_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_5/moving_mean:0 is illegal; using batch_normalization_5/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_5/moving_variance:0 is illegal; using batch_normalization_5/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_5/kernel:0 is illegal; using conv2d_5/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_5/bias:0 is illegal; using conv2d_5/bias_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_6/gamma:0 is illegal; using batch_normalization_6/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_6/beta:0 is illegal; using batch_normalization_6/beta_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_6/moving_mean:0 is illegal; using batch_normalization_6/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_6/moving_variance:0 is illegal; using batch_normalization_6/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_6/kernel:0 is illegal; using conv2d_6/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_6/bias:0 is illegal; using conv2d_6/bias_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_7/gamma:0 is illegal; using batch_normalization_7/gamma_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_7/beta:0 is illegal; using batch_normalization_7/beta_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_7/moving_mean:0 is illegal; using batch_normalization_7/moving_mean_0 instead.\n",
      "INFO:tensorflow:Summary name batch_normalization_7/moving_variance:0 is illegal; using batch_normalization_7/moving_variance_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_7/kernel:0 is illegal; using conv2d_7/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_7/bias:0 is illegal; using conv2d_7/bias_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_8/kernel:0 is illegal; using conv2d_8/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name conv2d_8/bias:0 is illegal; using conv2d_8/bias_0 instead.\n",
      "Epoch 1/100\n",
      "80/80 [==============================] - 1s - loss: 0.6993 - val_loss: 0.6932\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 0s - loss: 0.6991 - val_loss: 0.6931\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 0s - loss: 0.6989 - val_loss: 0.6931\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 0s - loss: 0.6988 - val_loss: 0.6932\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 0s - loss: 0.6986 - val_loss: 0.6932\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 0s - loss: 0.6985 - val_loss: 0.6932\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 0s - loss: 0.6983 - val_loss: 0.6932\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 0s - loss: 0.6982 - val_loss: 0.6932\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 0s - loss: 0.6981 - val_loss: 0.6932\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 0s - loss: 0.6979 - val_loss: 0.6932\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 0s - loss: 0.6978 - val_loss: 0.6932\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 0s - loss: 0.6977 - val_loss: 0.6932\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 0s - loss: 0.6976 - val_loss: 0.6932\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 0s - loss: 0.6975 - val_loss: 0.6932\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 0s - loss: 0.6974 - val_loss: 0.6932\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 0s - loss: 0.6973 - val_loss: 0.6932\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 0s - loss: 0.6971 - val_loss: 0.6932\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 0s - loss: 0.6970 - val_loss: 0.6932\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 0s - loss: 0.6970 - val_loss: 0.6932\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 0s - loss: 0.6969 - val_loss: 0.6932\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 0s - loss: 0.6968 - val_loss: 0.6932\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 0s - loss: 0.6967 - val_loss: 0.6932\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 0s - loss: 0.6966 - val_loss: 0.6932\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 0s - loss: 0.6965 - val_loss: 0.6932\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 0s - loss: 0.6964 - val_loss: 0.6932\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 0s - loss: 0.6963 - val_loss: 0.6932\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 0s - loss: 0.6963 - val_loss: 0.6932\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 0s - loss: 0.6962 - val_loss: 0.6932\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 0s - loss: 0.6961 - val_loss: 0.6932\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 0s - loss: 0.6961 - val_loss: 0.6932\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 0s - loss: 0.6960 - val_loss: 0.6932\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 0s - loss: 0.6959 - val_loss: 0.6932\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 0s - loss: 0.6959 - val_loss: 0.6932\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 0s - loss: 0.6958 - val_loss: 0.6932\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 0s - loss: 0.6957 - val_loss: 0.6932\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 0s - loss: 0.6957 - val_loss: 0.6932\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 0s - loss: 0.6956 - val_loss: 0.6932\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 0s - loss: 0.6956 - val_loss: 0.6932\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 0s - loss: 0.6955 - val_loss: 0.6932\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 0s - loss: 0.6954 - val_loss: 0.6932\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 0s - loss: 0.6954 - val_loss: 0.6932\n",
      "Epoch 42/100\n",
      "80/80 [==============================] - 0s - loss: 0.6953 - val_loss: 0.6932\n",
      "Epoch 43/100\n",
      "80/80 [==============================] - 0s - loss: 0.6953 - val_loss: 0.6932\n",
      "Epoch 44/100\n",
      "80/80 [==============================] - 0s - loss: 0.6952 - val_loss: 0.6932\n",
      "Epoch 45/100\n",
      "80/80 [==============================] - 0s - loss: 0.6952 - val_loss: 0.6932\n",
      "Epoch 46/100\n",
      "80/80 [==============================] - 0s - loss: 0.6951 - val_loss: 0.6932\n",
      "Epoch 47/100\n",
      "80/80 [==============================] - 0s - loss: 0.6951 - val_loss: 0.6932\n",
      "Epoch 48/100\n",
      "80/80 [==============================] - 0s - loss: 0.6950 - val_loss: 0.6932\n",
      "Epoch 49/100\n",
      "80/80 [==============================] - 0s - loss: 0.6950 - val_loss: 0.6932\n",
      "Epoch 50/100\n",
      "80/80 [==============================] - 0s - loss: 0.6950 - val_loss: 0.6932\n",
      "Epoch 51/100\n",
      "80/80 [==============================] - 0s - loss: 0.6949 - val_loss: 0.6932\n",
      "Epoch 52/100\n",
      "80/80 [==============================] - 0s - loss: 0.6949 - val_loss: 0.6932\n",
      "Epoch 53/100\n",
      "80/80 [==============================] - 0s - loss: 0.6948 - val_loss: 0.6932\n",
      "Epoch 54/100\n",
      "80/80 [==============================] - 0s - loss: 0.6948 - val_loss: 0.6932\n",
      "Epoch 55/100\n",
      "80/80 [==============================] - 0s - loss: 0.6947 - val_loss: 0.6932\n",
      "Epoch 56/100\n",
      "80/80 [==============================] - 0s - loss: 0.6947 - val_loss: 0.6932\n",
      "Epoch 57/100\n",
      "80/80 [==============================] - 0s - loss: 0.6947 - val_loss: 0.6932\n",
      "Epoch 58/100\n",
      "80/80 [==============================] - 0s - loss: 0.6946 - val_loss: 0.6932\n",
      "Epoch 59/100\n",
      "80/80 [==============================] - 0s - loss: 0.6946 - val_loss: 0.6932\n",
      "Epoch 60/100\n",
      "80/80 [==============================] - 0s - loss: 0.6946 - val_loss: 0.6933\n",
      "Epoch 61/100\n",
      "80/80 [==============================] - 0s - loss: 0.6945 - val_loss: 0.6933\n",
      "Epoch 62/100\n",
      "80/80 [==============================] - 0s - loss: 0.6945 - val_loss: 0.6933\n",
      "Epoch 63/100\n",
      "80/80 [==============================] - 0s - loss: 0.6944 - val_loss: 0.6933\n",
      "Epoch 64/100\n",
      "80/80 [==============================] - 0s - loss: 0.6944 - val_loss: 0.6933\n",
      "Epoch 65/100\n",
      "80/80 [==============================] - 0s - loss: 0.6944 - val_loss: 0.6933\n",
      "Epoch 66/100\n",
      "80/80 [==============================] - 0s - loss: 0.6943 - val_loss: 0.6933\n",
      "Epoch 67/100\n",
      "80/80 [==============================] - 0s - loss: 0.6943 - val_loss: 0.6933\n",
      "Epoch 68/100\n",
      "80/80 [==============================] - 0s - loss: 0.6943 - val_loss: 0.6933\n",
      "Epoch 69/100\n",
      "80/80 [==============================] - 0s - loss: 0.6943 - val_loss: 0.6933\n",
      "Epoch 70/100\n",
      "80/80 [==============================] - 0s - loss: 0.6942 - val_loss: 0.6933\n",
      "Epoch 71/100\n",
      "80/80 [==============================] - 0s - loss: 0.6942 - val_loss: 0.6933\n",
      "Epoch 72/100\n",
      "80/80 [==============================] - 0s - loss: 0.6942 - val_loss: 0.6933\n",
      "Epoch 73/100\n",
      "80/80 [==============================] - 0s - loss: 0.6941 - val_loss: 0.6933\n",
      "Epoch 74/100\n",
      "80/80 [==============================] - 0s - loss: 0.6941 - val_loss: 0.6933\n",
      "Epoch 75/100\n",
      "80/80 [==============================] - 0s - loss: 0.6941 - val_loss: 0.6933\n",
      "Epoch 76/100\n",
      "80/80 [==============================] - 0s - loss: 0.6940 - val_loss: 0.6933\n",
      "Epoch 77/100\n",
      "80/80 [==============================] - 0s - loss: 0.6940 - val_loss: 0.6933\n",
      "Epoch 78/100\n",
      "80/80 [==============================] - 0s - loss: 0.6940 - val_loss: 0.6933\n",
      "Epoch 79/100\n",
      "80/80 [==============================] - 0s - loss: 0.6940 - val_loss: 0.6933\n",
      "Epoch 80/100\n",
      "80/80 [==============================] - 0s - loss: 0.6939 - val_loss: 0.6933\n",
      "Epoch 81/100\n",
      "80/80 [==============================] - 0s - loss: 0.6939 - val_loss: 0.6933\n",
      "Epoch 82/100\n",
      "80/80 [==============================] - 0s - loss: 0.6939 - val_loss: 0.6933\n",
      "Epoch 83/100\n",
      "80/80 [==============================] - 0s - loss: 0.6938 - val_loss: 0.6933\n",
      "Epoch 84/100\n",
      "80/80 [==============================] - 0s - loss: 0.6938 - val_loss: 0.6933\n",
      "Epoch 85/100\n",
      "80/80 [==============================] - 0s - loss: 0.6938 - val_loss: 0.6933\n",
      "Epoch 86/100\n",
      "80/80 [==============================] - 0s - loss: 0.6938 - val_loss: 0.6933\n",
      "Epoch 87/100\n",
      "80/80 [==============================] - 0s - loss: 0.6937 - val_loss: 0.6933\n",
      "Epoch 88/100\n",
      "80/80 [==============================] - 0s - loss: 0.6937 - val_loss: 0.6933\n",
      "Epoch 89/100\n",
      "80/80 [==============================] - 0s - loss: 0.6937 - val_loss: 0.6933\n",
      "Epoch 90/100\n",
      "80/80 [==============================] - 0s - loss: 0.6937 - val_loss: 0.6933\n",
      "Epoch 91/100\n",
      "80/80 [==============================] - 0s - loss: 0.6937 - val_loss: 0.6933\n",
      "Epoch 92/100\n",
      "80/80 [==============================] - 0s - loss: 0.6936 - val_loss: 0.6933\n",
      "Epoch 93/100\n",
      "80/80 [==============================] - 0s - loss: 0.6936 - val_loss: 0.6933\n",
      "Epoch 94/100\n",
      "80/80 [==============================] - 0s - loss: 0.6936 - val_loss: 0.6933\n",
      "Epoch 95/100\n",
      "80/80 [==============================] - 0s - loss: 0.6936 - val_loss: 0.6933\n",
      "Epoch 96/100\n",
      "80/80 [==============================] - 0s - loss: 0.6935 - val_loss: 0.6933\n",
      "Epoch 97/100\n",
      "80/80 [==============================] - 0s - loss: 0.6935 - val_loss: 0.6933\n",
      "Epoch 98/100\n",
      "80/80 [==============================] - 0s - loss: 0.6935 - val_loss: 0.6933\n",
      "Epoch 99/100\n",
      "80/80 [==============================] - 0s - loss: 0.6935 - val_loss: 0.6933\n",
      "Epoch 100/100\n",
      "80/80 [==============================] - 0s - loss: 0.6934 - val_loss: 0.6933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb81c71aef0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, batch_size, epochs, validation_split=0.2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
